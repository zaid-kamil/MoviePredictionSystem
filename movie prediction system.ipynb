{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =pd.read_csv('credits.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'/home/digipodium/Desktop/keywords.csv' does not exist",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-eed24c2b9ccf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata1\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/digipodium/Desktop/keywords.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1693\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'/home/digipodium/Desktop/keywords.csv' does not exist"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "data1 =pd.read_csv('keywords.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'/home/digipodium/Desktop/links.csv' does not exist",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-054306be8006>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata2\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/digipodium/Desktop/links.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1693\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'/home/digipodium/Desktop/links.csv' does not exist"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "data2 =pd.read_csv('links.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 =pd.read_csv('links_small.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\Anaconda4\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2698: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "data4 =pd.read_csv('movies_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data5 =pd.read_csv('ratings.csv.crdownload')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data6 =pd.read_csv('/home/digipodium/Desktop/Datasets/ratings_small.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data7 =pd.read_csv('/home/digipodium/Desktop/Datasets/tmdb_5000_credits.csv.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data8 =pd.read_csv('/home/digipodium/Desktop/Datasets/tmdb_5000_movies.csv.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45476 entries, 0 to 45475\n",
      "Data columns (total 3 columns):\n",
      "cast    45476 non-null object\n",
      "crew    45476 non-null object\n",
      "id      45476 non-null int64\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cast</th>\n",
       "      <th>crew</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'cast_id': 14, 'character': 'Woody (voice)',...</td>\n",
       "      <td>[{'credit_id': '52fe4284c3a36847f8024f49', 'de...</td>\n",
       "      <td>862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'cast_id': 1, 'character': 'Alan Parrish', '...</td>\n",
       "      <td>[{'credit_id': '52fe44bfc3a36847f80a7cd1', 'de...</td>\n",
       "      <td>8844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'cast_id': 2, 'character': 'Max Goldman', 'c...</td>\n",
       "      <td>[{'credit_id': '52fe466a9251416c75077a89', 'de...</td>\n",
       "      <td>15602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'cast_id': 1, 'character': \"Savannah 'Vannah...</td>\n",
       "      <td>[{'credit_id': '52fe44779251416c91011acb', 'de...</td>\n",
       "      <td>31357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'cast_id': 1, 'character': 'George Banks', '...</td>\n",
       "      <td>[{'credit_id': '52fe44959251416c75039ed7', 'de...</td>\n",
       "      <td>11862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[{'cast_id': 25, 'character': 'Lt. Vincent Han...</td>\n",
       "      <td>[{'credit_id': '52fe4292c3a36847f802916d', 'de...</td>\n",
       "      <td>949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[{'cast_id': 1, 'character': 'Linus Larrabee',...</td>\n",
       "      <td>[{'credit_id': '52fe44959251416c75039da9', 'de...</td>\n",
       "      <td>11860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[{'cast_id': 2, 'character': 'Tom Sawyer', 'cr...</td>\n",
       "      <td>[{'credit_id': '52fe46bdc3a36847f810f797', 'de...</td>\n",
       "      <td>45325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[{'cast_id': 1, 'character': 'Darren Francis T...</td>\n",
       "      <td>[{'credit_id': '52fe44dbc3a36847f80ae0f1', 'de...</td>\n",
       "      <td>9091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[{'cast_id': 1, 'character': 'James Bond', 'cr...</td>\n",
       "      <td>[{'credit_id': '52fe426ec3a36847f801e14b', 'de...</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[{'cast_id': 1, 'character': 'Andrew Shepherd'...</td>\n",
       "      <td>[{'credit_id': '52fe44dac3a36847f80adfa3', 'de...</td>\n",
       "      <td>9087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[{'cast_id': 9, 'character': 'Count Dracula', ...</td>\n",
       "      <td>[{'credit_id': '52fe44b79251416c7503e7fb', 'de...</td>\n",
       "      <td>12110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[{'cast_id': 1, 'character': 'Balto (voice)', ...</td>\n",
       "      <td>[{'credit_id': '593f24b9c3a3680369002371', 'de...</td>\n",
       "      <td>21032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[{'cast_id': 1, 'character': 'Richard Nixon', ...</td>\n",
       "      <td>[{'credit_id': '52fe43c59251416c7501d6f3', 'de...</td>\n",
       "      <td>10858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[{'cast_id': 1, 'character': 'Morgan Adams', '...</td>\n",
       "      <td>[{'credit_id': '52fe42f4c3a36847f802f69f', 'de...</td>\n",
       "      <td>1408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[{'cast_id': 4, 'character': \"Sam 'Ace' Rothst...</td>\n",
       "      <td>[{'credit_id': '52fe424dc3a36847f80139cd', 'de...</td>\n",
       "      <td>524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[{'cast_id': 6, 'character': 'Marianne Dashwoo...</td>\n",
       "      <td>[{'credit_id': '52fe43cec3a36847f807101f', 'de...</td>\n",
       "      <td>4584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[{'cast_id': 42, 'character': 'Ted the Bellhop...</td>\n",
       "      <td>[{'credit_id': '52fe420dc3a36847f800011b', 'de...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[{'cast_id': 1, 'character': 'Ace Ventura', 'c...</td>\n",
       "      <td>[{'credit_id': '52fe44dfc3a36847f80af28b', 'de...</td>\n",
       "      <td>9273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[{'cast_id': 1, 'character': 'John', 'credit_i...</td>\n",
       "      <td>[{'credit_id': '52fe44509251416c750305a1', 'de...</td>\n",
       "      <td>11517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[{'cast_id': 1, 'character': 'Chili Palmer', '...</td>\n",
       "      <td>[{'credit_id': '52fe448dc3a36847f809c729', 'de...</td>\n",
       "      <td>8012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[{'cast_id': 8, 'character': 'Helen Hudson', '...</td>\n",
       "      <td>[{'credit_id': '52fe430ec3a36847f803722d', 'de...</td>\n",
       "      <td>1710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[{'cast_id': 1, 'character': 'Robert Rath', 'c...</td>\n",
       "      <td>[{'credit_id': '52fe451cc3a36847f80bd145', 'de...</td>\n",
       "      <td>9691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[{'cast_id': 1, 'character': 'Jessie Caldwell'...</td>\n",
       "      <td>[{'credit_id': '52fe45129251416c7504ab67', 'de...</td>\n",
       "      <td>12665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[{'cast_id': 1, 'character': 'Ben Sanderson', ...</td>\n",
       "      <td>[{'credit_id': '52fe4245c3a36847f80111c3', 'de...</td>\n",
       "      <td>451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[{'cast_id': 2, 'character': 'Othello', 'credi...</td>\n",
       "      <td>[{'credit_id': '5462510ec3a368082d000121', 'de...</td>\n",
       "      <td>16420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[{'cast_id': 9, 'character': 'Young Roberta Ma...</td>\n",
       "      <td>[{'credit_id': '52fe44dec3a36847f80aed45', 'de...</td>\n",
       "      <td>9263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[{'cast_id': 1, 'character': 'Anne Elliott', '...</td>\n",
       "      <td>[{'credit_id': '52fe46ff9251416c7508a8b3', 'de...</td>\n",
       "      <td>17015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[{'cast_id': 24, 'character': 'One', 'credit_i...</td>\n",
       "      <td>[{'credit_id': '52fe428ac3a36847f8026c6f', 'de...</td>\n",
       "      <td>902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[{'cast_id': 2, 'character': 'Xiao Jingbao', '...</td>\n",
       "      <td>[{'credit_id': '52fe46559251416c910511c9', 'de...</td>\n",
       "      <td>37557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3970</th>\n",
       "      <td>[{'cast_id': 2, 'character': '', 'credit_id': ...</td>\n",
       "      <td>[{'credit_id': '52fe4a379251416c910c7181', 'de...</td>\n",
       "      <td>89992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3971</th>\n",
       "      <td>[{'cast_id': 2, 'character': 'Julie Rose / Kat...</td>\n",
       "      <td>[{'credit_id': '52fe47efc3a368484e0e144b', 'de...</td>\n",
       "      <td>70199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3972</th>\n",
       "      <td>[{'cast_id': 4, 'character': 'Gretta Conroy', ...</td>\n",
       "      <td>[{'credit_id': '52fe47209251416c9106adfd', 'de...</td>\n",
       "      <td>39507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3973</th>\n",
       "      <td>[{'cast_id': 1, 'character': 'Gunnery Sgt. Bur...</td>\n",
       "      <td>[{'credit_id': '571c239ac3a36823cb002c5c', 'de...</td>\n",
       "      <td>62185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3974</th>\n",
       "      <td>[{'cast_id': 2, 'character': 'Markie', 'credit...</td>\n",
       "      <td>[{'credit_id': '52fe44acc3a368484e0304c3', 'de...</td>\n",
       "      <td>24826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3975</th>\n",
       "      <td>[{'cast_id': 1, 'character': 'Sam', 'credit_id...</td>\n",
       "      <td>[{'credit_id': '52fe44529251416c9100caf9', 'de...</td>\n",
       "      <td>30994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3976</th>\n",
       "      <td>[{'cast_id': 2, 'character': 'Himself', 'credi...</td>\n",
       "      <td>[{'credit_id': '52fe470a9251416c7508bf65', 'de...</td>\n",
       "      <td>17159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3977</th>\n",
       "      <td>[{'cast_id': 1, 'character': \"Jim 'Jamie' Grah...</td>\n",
       "      <td>[{'credit_id': '52fe43299251416c75005c95', 'de...</td>\n",
       "      <td>10110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3978</th>\n",
       "      <td>[{'cast_id': 1, 'character': 'Ernest P. Worrel...</td>\n",
       "      <td>[{'credit_id': '52fe47ac9251416c750a1a19', 'de...</td>\n",
       "      <td>18935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3979</th>\n",
       "      <td>[{'cast_id': 16, 'character': \"Ashley 'Ash' J....</td>\n",
       "      <td>[{'credit_id': '52fe4273c3a36847f801f7e3', 'de...</td>\n",
       "      <td>764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3980</th>\n",
       "      <td>[{'cast_id': 1, 'character': 'Jack Benteen', '...</td>\n",
       "      <td>[{'credit_id': '52fe43dfc3a368484e0031f9', 'de...</td>\n",
       "      <td>20287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3981</th>\n",
       "      <td>[{'cast_id': 3, 'character': 'Stan', 'credit_i...</td>\n",
       "      <td>[{'credit_id': '52fe4525c3a368484e04b003', 'de...</td>\n",
       "      <td>26964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3982</th>\n",
       "      <td>[{'cast_id': 1, 'character': 'Linda', 'credit_...</td>\n",
       "      <td>[{'credit_id': '52fe484dc3a368484e0f20cf', 'de...</td>\n",
       "      <td>71881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3983</th>\n",
       "      <td>[{'cast_id': 2, 'character': 'Olivia Foxworth'...</td>\n",
       "      <td>[{'credit_id': '52fe466f9251416c750783d7', 'de...</td>\n",
       "      <td>15658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3984</th>\n",
       "      <td>[{'cast_id': 8, 'character': 'Brian Harcourt-S...</td>\n",
       "      <td>[{'credit_id': '52fe43e2c3a36847f8076271', 'de...</td>\n",
       "      <td>4918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3985</th>\n",
       "      <td>[{'cast_id': 1, 'character': 'Sgt. Clell Hazar...</td>\n",
       "      <td>[{'credit_id': '52fe4590c3a368484e06276b', 'de...</td>\n",
       "      <td>28368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3986</th>\n",
       "      <td>[{'cast_id': 2, 'character': 'Giulia', 'credit...</td>\n",
       "      <td>[{'credit_id': '52fe4954c3a36847f8194935', 'de...</td>\n",
       "      <td>58084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3987</th>\n",
       "      <td>[{'cast_id': 1, 'character': 'Amanda Wingfield...</td>\n",
       "      <td>[{'credit_id': '52fe4842c3a36847f815e893', 'de...</td>\n",
       "      <td>52780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3988</th>\n",
       "      <td>[{'cast_id': 24, 'character': 'Nicola Bonnano'...</td>\n",
       "      <td>[{'credit_id': '52fe4756c3a36847f81302d9', 'de...</td>\n",
       "      <td>48149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3989</th>\n",
       "      <td>[{'cast_id': 1, 'character': 'Andrew Morenski ...</td>\n",
       "      <td>[{'credit_id': '52fe44f0c3a368484e03f84b', 'de...</td>\n",
       "      <td>26156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3990</th>\n",
       "      <td>[{'cast_id': 1, 'character': 'Bobby Taylor', '...</td>\n",
       "      <td>[{'credit_id': '52fe45539251416c9102e839', 'de...</td>\n",
       "      <td>34101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3991</th>\n",
       "      <td>[{'cast_id': 3, 'character': 'Bill Rowan', 'cr...</td>\n",
       "      <td>[{'credit_id': '52fe44b59251416c9101a2ab', 'de...</td>\n",
       "      <td>32054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3992</th>\n",
       "      <td>[{'cast_id': 1, 'character': 'Dan Bartlett', '...</td>\n",
       "      <td>[{'credit_id': '52fe45f79251416c7506897f', 'de...</td>\n",
       "      <td>14464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3993</th>\n",
       "      <td>[{'cast_id': 1, 'character': 'Sylvie', 'credit...</td>\n",
       "      <td>[{'credit_id': '52fe470dc3a368484e0b2633', 'de...</td>\n",
       "      <td>65501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3994</th>\n",
       "      <td>[{'cast_id': 1, 'character': 'Hunk Golden', 'c...</td>\n",
       "      <td>[{'credit_id': '52fe44c59251416c9101c4cf', 'de...</td>\n",
       "      <td>32227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>[{'cast_id': 1, 'character': 'Jack Putter', 'c...</td>\n",
       "      <td>[{'credit_id': '52fe4360c3a36847f804f92d', 'de...</td>\n",
       "      <td>2614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>[{'cast_id': 1, 'character': 'Francis Phelan',...</td>\n",
       "      <td>[{'credit_id': '56436304c3a36870ef0023cf', 'de...</td>\n",
       "      <td>40962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>[{'cast_id': 1, 'character': 'Lyle Rogers', 'c...</td>\n",
       "      <td>[{'credit_id': '52fe45179251416c7504b66f', 'de...</td>\n",
       "      <td>12704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>[{'cast_id': 17, 'character': 'Ellen Brody', '...</td>\n",
       "      <td>[{'credit_id': '52fe4255c3a36847f8016259', 'de...</td>\n",
       "      <td>580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>[{'cast_id': 2, 'character': 'Leonard Parker',...</td>\n",
       "      <td>[{'credit_id': '54ebc3fac3a3686d6d0001e5', 'de...</td>\n",
       "      <td>24828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   cast  \\\n",
       "0     [{'cast_id': 14, 'character': 'Woody (voice)',...   \n",
       "1     [{'cast_id': 1, 'character': 'Alan Parrish', '...   \n",
       "2     [{'cast_id': 2, 'character': 'Max Goldman', 'c...   \n",
       "3     [{'cast_id': 1, 'character': \"Savannah 'Vannah...   \n",
       "4     [{'cast_id': 1, 'character': 'George Banks', '...   \n",
       "5     [{'cast_id': 25, 'character': 'Lt. Vincent Han...   \n",
       "6     [{'cast_id': 1, 'character': 'Linus Larrabee',...   \n",
       "7     [{'cast_id': 2, 'character': 'Tom Sawyer', 'cr...   \n",
       "8     [{'cast_id': 1, 'character': 'Darren Francis T...   \n",
       "9     [{'cast_id': 1, 'character': 'James Bond', 'cr...   \n",
       "10    [{'cast_id': 1, 'character': 'Andrew Shepherd'...   \n",
       "11    [{'cast_id': 9, 'character': 'Count Dracula', ...   \n",
       "12    [{'cast_id': 1, 'character': 'Balto (voice)', ...   \n",
       "13    [{'cast_id': 1, 'character': 'Richard Nixon', ...   \n",
       "14    [{'cast_id': 1, 'character': 'Morgan Adams', '...   \n",
       "15    [{'cast_id': 4, 'character': \"Sam 'Ace' Rothst...   \n",
       "16    [{'cast_id': 6, 'character': 'Marianne Dashwoo...   \n",
       "17    [{'cast_id': 42, 'character': 'Ted the Bellhop...   \n",
       "18    [{'cast_id': 1, 'character': 'Ace Ventura', 'c...   \n",
       "19    [{'cast_id': 1, 'character': 'John', 'credit_i...   \n",
       "20    [{'cast_id': 1, 'character': 'Chili Palmer', '...   \n",
       "21    [{'cast_id': 8, 'character': 'Helen Hudson', '...   \n",
       "22    [{'cast_id': 1, 'character': 'Robert Rath', 'c...   \n",
       "23    [{'cast_id': 1, 'character': 'Jessie Caldwell'...   \n",
       "24    [{'cast_id': 1, 'character': 'Ben Sanderson', ...   \n",
       "25    [{'cast_id': 2, 'character': 'Othello', 'credi...   \n",
       "26    [{'cast_id': 9, 'character': 'Young Roberta Ma...   \n",
       "27    [{'cast_id': 1, 'character': 'Anne Elliott', '...   \n",
       "28    [{'cast_id': 24, 'character': 'One', 'credit_i...   \n",
       "29    [{'cast_id': 2, 'character': 'Xiao Jingbao', '...   \n",
       "...                                                 ...   \n",
       "3970  [{'cast_id': 2, 'character': '', 'credit_id': ...   \n",
       "3971  [{'cast_id': 2, 'character': 'Julie Rose / Kat...   \n",
       "3972  [{'cast_id': 4, 'character': 'Gretta Conroy', ...   \n",
       "3973  [{'cast_id': 1, 'character': 'Gunnery Sgt. Bur...   \n",
       "3974  [{'cast_id': 2, 'character': 'Markie', 'credit...   \n",
       "3975  [{'cast_id': 1, 'character': 'Sam', 'credit_id...   \n",
       "3976  [{'cast_id': 2, 'character': 'Himself', 'credi...   \n",
       "3977  [{'cast_id': 1, 'character': \"Jim 'Jamie' Grah...   \n",
       "3978  [{'cast_id': 1, 'character': 'Ernest P. Worrel...   \n",
       "3979  [{'cast_id': 16, 'character': \"Ashley 'Ash' J....   \n",
       "3980  [{'cast_id': 1, 'character': 'Jack Benteen', '...   \n",
       "3981  [{'cast_id': 3, 'character': 'Stan', 'credit_i...   \n",
       "3982  [{'cast_id': 1, 'character': 'Linda', 'credit_...   \n",
       "3983  [{'cast_id': 2, 'character': 'Olivia Foxworth'...   \n",
       "3984  [{'cast_id': 8, 'character': 'Brian Harcourt-S...   \n",
       "3985  [{'cast_id': 1, 'character': 'Sgt. Clell Hazar...   \n",
       "3986  [{'cast_id': 2, 'character': 'Giulia', 'credit...   \n",
       "3987  [{'cast_id': 1, 'character': 'Amanda Wingfield...   \n",
       "3988  [{'cast_id': 24, 'character': 'Nicola Bonnano'...   \n",
       "3989  [{'cast_id': 1, 'character': 'Andrew Morenski ...   \n",
       "3990  [{'cast_id': 1, 'character': 'Bobby Taylor', '...   \n",
       "3991  [{'cast_id': 3, 'character': 'Bill Rowan', 'cr...   \n",
       "3992  [{'cast_id': 1, 'character': 'Dan Bartlett', '...   \n",
       "3993  [{'cast_id': 1, 'character': 'Sylvie', 'credit...   \n",
       "3994  [{'cast_id': 1, 'character': 'Hunk Golden', 'c...   \n",
       "3995  [{'cast_id': 1, 'character': 'Jack Putter', 'c...   \n",
       "3996  [{'cast_id': 1, 'character': 'Francis Phelan',...   \n",
       "3997  [{'cast_id': 1, 'character': 'Lyle Rogers', 'c...   \n",
       "3998  [{'cast_id': 17, 'character': 'Ellen Brody', '...   \n",
       "3999  [{'cast_id': 2, 'character': 'Leonard Parker',...   \n",
       "\n",
       "                                                   crew     id  \n",
       "0     [{'credit_id': '52fe4284c3a36847f8024f49', 'de...    862  \n",
       "1     [{'credit_id': '52fe44bfc3a36847f80a7cd1', 'de...   8844  \n",
       "2     [{'credit_id': '52fe466a9251416c75077a89', 'de...  15602  \n",
       "3     [{'credit_id': '52fe44779251416c91011acb', 'de...  31357  \n",
       "4     [{'credit_id': '52fe44959251416c75039ed7', 'de...  11862  \n",
       "5     [{'credit_id': '52fe4292c3a36847f802916d', 'de...    949  \n",
       "6     [{'credit_id': '52fe44959251416c75039da9', 'de...  11860  \n",
       "7     [{'credit_id': '52fe46bdc3a36847f810f797', 'de...  45325  \n",
       "8     [{'credit_id': '52fe44dbc3a36847f80ae0f1', 'de...   9091  \n",
       "9     [{'credit_id': '52fe426ec3a36847f801e14b', 'de...    710  \n",
       "10    [{'credit_id': '52fe44dac3a36847f80adfa3', 'de...   9087  \n",
       "11    [{'credit_id': '52fe44b79251416c7503e7fb', 'de...  12110  \n",
       "12    [{'credit_id': '593f24b9c3a3680369002371', 'de...  21032  \n",
       "13    [{'credit_id': '52fe43c59251416c7501d6f3', 'de...  10858  \n",
       "14    [{'credit_id': '52fe42f4c3a36847f802f69f', 'de...   1408  \n",
       "15    [{'credit_id': '52fe424dc3a36847f80139cd', 'de...    524  \n",
       "16    [{'credit_id': '52fe43cec3a36847f807101f', 'de...   4584  \n",
       "17    [{'credit_id': '52fe420dc3a36847f800011b', 'de...      5  \n",
       "18    [{'credit_id': '52fe44dfc3a36847f80af28b', 'de...   9273  \n",
       "19    [{'credit_id': '52fe44509251416c750305a1', 'de...  11517  \n",
       "20    [{'credit_id': '52fe448dc3a36847f809c729', 'de...   8012  \n",
       "21    [{'credit_id': '52fe430ec3a36847f803722d', 'de...   1710  \n",
       "22    [{'credit_id': '52fe451cc3a36847f80bd145', 'de...   9691  \n",
       "23    [{'credit_id': '52fe45129251416c7504ab67', 'de...  12665  \n",
       "24    [{'credit_id': '52fe4245c3a36847f80111c3', 'de...    451  \n",
       "25    [{'credit_id': '5462510ec3a368082d000121', 'de...  16420  \n",
       "26    [{'credit_id': '52fe44dec3a36847f80aed45', 'de...   9263  \n",
       "27    [{'credit_id': '52fe46ff9251416c7508a8b3', 'de...  17015  \n",
       "28    [{'credit_id': '52fe428ac3a36847f8026c6f', 'de...    902  \n",
       "29    [{'credit_id': '52fe46559251416c910511c9', 'de...  37557  \n",
       "...                                                 ...    ...  \n",
       "3970  [{'credit_id': '52fe4a379251416c910c7181', 'de...  89992  \n",
       "3971  [{'credit_id': '52fe47efc3a368484e0e144b', 'de...  70199  \n",
       "3972  [{'credit_id': '52fe47209251416c9106adfd', 'de...  39507  \n",
       "3973  [{'credit_id': '571c239ac3a36823cb002c5c', 'de...  62185  \n",
       "3974  [{'credit_id': '52fe44acc3a368484e0304c3', 'de...  24826  \n",
       "3975  [{'credit_id': '52fe44529251416c9100caf9', 'de...  30994  \n",
       "3976  [{'credit_id': '52fe470a9251416c7508bf65', 'de...  17159  \n",
       "3977  [{'credit_id': '52fe43299251416c75005c95', 'de...  10110  \n",
       "3978  [{'credit_id': '52fe47ac9251416c750a1a19', 'de...  18935  \n",
       "3979  [{'credit_id': '52fe4273c3a36847f801f7e3', 'de...    764  \n",
       "3980  [{'credit_id': '52fe43dfc3a368484e0031f9', 'de...  20287  \n",
       "3981  [{'credit_id': '52fe4525c3a368484e04b003', 'de...  26964  \n",
       "3982  [{'credit_id': '52fe484dc3a368484e0f20cf', 'de...  71881  \n",
       "3983  [{'credit_id': '52fe466f9251416c750783d7', 'de...  15658  \n",
       "3984  [{'credit_id': '52fe43e2c3a36847f8076271', 'de...   4918  \n",
       "3985  [{'credit_id': '52fe4590c3a368484e06276b', 'de...  28368  \n",
       "3986  [{'credit_id': '52fe4954c3a36847f8194935', 'de...  58084  \n",
       "3987  [{'credit_id': '52fe4842c3a36847f815e893', 'de...  52780  \n",
       "3988  [{'credit_id': '52fe4756c3a36847f81302d9', 'de...  48149  \n",
       "3989  [{'credit_id': '52fe44f0c3a368484e03f84b', 'de...  26156  \n",
       "3990  [{'credit_id': '52fe45539251416c9102e839', 'de...  34101  \n",
       "3991  [{'credit_id': '52fe44b59251416c9101a2ab', 'de...  32054  \n",
       "3992  [{'credit_id': '52fe45f79251416c7506897f', 'de...  14464  \n",
       "3993  [{'credit_id': '52fe470dc3a368484e0b2633', 'de...  65501  \n",
       "3994  [{'credit_id': '52fe44c59251416c9101c4cf', 'de...  32227  \n",
       "3995  [{'credit_id': '52fe4360c3a36847f804f92d', 'de...   2614  \n",
       "3996  [{'credit_id': '56436304c3a36870ef0023cf', 'de...  40962  \n",
       "3997  [{'credit_id': '52fe45179251416c7504b66f', 'de...  12704  \n",
       "3998  [{'credit_id': '52fe4255c3a36847f8016259', 'de...    580  \n",
       "3999  [{'credit_id': '54ebc3fac3a3686d6d0001e5', 'de...  24828  \n",
       "\n",
       "[4000 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "#___________________________\n",
    "def load_tmdb_movies(path):\n",
    "    df = pd.read_csv(path)\n",
    "    df['release_date'] = pd.to_datetime(df['release_date']).apply(lambda x: x.date())\n",
    "    json_columns = ['genres', 'keywords', 'production_countries',\n",
    "                    'production_companies', 'spoken_languages']\n",
    "    for column in json_columns:\n",
    "        df[column] = df[column].apply(json.loads)\n",
    "    return df\n",
    "#___________________________\n",
    "def load_tmdb_credits(path):\n",
    "    df = pd.read_csv(path)\n",
    "    json_columns = ['cast', 'crew']\n",
    "    for column in json_columns:\n",
    "        df[column] = df[column].apply(json.loads)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#___________________\n",
    "LOST_COLUMNS = [\n",
    "    'actor_1_facebook_likes',\n",
    "    'actor_2_facebook_likes',\n",
    "    'actor_3_facebook_likes',\n",
    "    'aspect_ratio',\n",
    "    'cast_total_facebook_likes',\n",
    "    'color',\n",
    "    'content_rating',\n",
    "    'director_facebook_likes',\n",
    "    'facenumber_in_poster',\n",
    "    'movie_facebook_likes',\n",
    "    'movie_imdb_link',\n",
    "    'num_critic_for_reviews',\n",
    "    'num_user_for_reviews']\n",
    "#____________________________________\n",
    "TMDB_TO_IMDB_SIMPLE_EQUIVALENCIES = {\n",
    "    'budget': 'budget',\n",
    "    'genres': 'genres',\n",
    "    'revenue': 'gross',\n",
    "    'title': 'movie_title',\n",
    "    'runtime': 'duration',\n",
    "    'original_language': 'language',\n",
    "    'keywords': 'plot_keywords',\n",
    "    'vote_count': 'num_voted_users'}\n",
    "#_____________________________________________________\n",
    "IMDB_COLUMNS_TO_REMAP = {'imdb_score': 'vote_average'}\n",
    "#_____________________________________________________\n",
    "def safe_access(container, index_values):\n",
    "    # return missing value rather than an error upon indexing/key failure\n",
    "    result = container\n",
    "    try:\n",
    "        for idx in index_values:\n",
    "            result = result[idx]\n",
    "        return result\n",
    "    except IndexError or KeyError:\n",
    "        return pd.np.nan\n",
    "#_____________________________________________________\n",
    "def get_director(crew_data):\n",
    "    directors = [x['name'] for x in crew_data if x['job'] == 'Director']\n",
    "    return safe_access(directors, [0])\n",
    "#_____________________________________________________\n",
    "def pipe_flatten_names(keywords):\n",
    "    return '|'.join([x['name'] for x in keywords])\n",
    "#_____________________________________________________\n",
    "def convert_to_original_format(movies, credits):\n",
    "    tmdb_movies = movies.copy()\n",
    "    tmdb_movies.rename(columns=TMDB_TO_IMDB_SIMPLE_EQUIVALENCIES, inplace=True)\n",
    "    tmdb_movies['title_year'] = pd.to_datetime(tmdb_movies['release_date']).apply(lambda x: x.year)\n",
    "    # I'm assuming that the first production country is equivalent, but have not been able to validate this\n",
    "    tmdb_movies['country'] = tmdb_movies['production_countries'].apply(lambda x: safe_access(x, [0, 'name']))\n",
    "    tmdb_movies['language'] = tmdb_movies['spoken_languages'].apply(lambda x: safe_access(x, [0, 'name']))\n",
    "    tmdb_movies['director_name'] = credits['crew'].apply(get_director)\n",
    "    tmdb_movies['actor_1_name'] = credits['cast'].apply(lambda x: safe_access(x, [1, 'name']))\n",
    "    tmdb_movies['actor_2_name'] = credits['cast'].apply(lambda x: safe_access(x, [2, 'name']))\n",
    "    tmdb_movies['actor_3_name'] = credits['cast'].apply(lambda x: safe_access(x, [3, 'name']))\n",
    "    tmdb_movies['genres'] = tmdb_movies['genres'].apply(pipe_flatten_names)\n",
    "    tmdb_movies['plot_keywords'] = tmdb_movies['plot_keywords'].apply(pipe_flatten_names)\n",
    "    return tmdb_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] The system cannot find the file specified",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-510751a40031>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msubprocess\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcheck_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheck_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"dir\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"E:\\\\Project\\\\Datasets\\\\tmdb_5000_movies.csv.zip\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"utf8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda4\\lib\\subprocess.py\u001b[0m in \u001b[0;36mcheck_output\u001b[1;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m     return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n\u001b[1;32m--> 336\u001b[1;33m                **kwargs).stdout\n\u001b[0m\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda4\\lib\\subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(input, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    401\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'stdin'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPIPE\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 403\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mprocess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    404\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m             \u001b[0mstdout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda4\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors)\u001b[0m\n\u001b[0;32m    707\u001b[0m                                 \u001b[0mc2pread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc2pwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    708\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 709\u001b[1;33m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[0;32m    710\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    711\u001b[0m             \u001b[1;31m# Cleanup if the child failed starting.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda4\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session)\u001b[0m\n\u001b[0;32m    995\u001b[0m                                          \u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m                                          \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcwd\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcwd\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 997\u001b[1;33m                                          startupinfo)\n\u001b[0m\u001b[0;32m    998\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m                 \u001b[1;31m# Child is launched. Close the parent's copy of those pipe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "from subprocess import check_output\n",
    "print(check_output([\"ls\",\"/home/digipodium/Desktop/Datasets/tmdb_5000_movies.csv.zip\"]).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fuzzywuzzy'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-67308df3d9ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneighbors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNearestNeighbors\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mfuzzywuzzy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfuzz\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSTOPWORDS\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"patch.force_edgecolor\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'fuzzywuzzy'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math, nltk, warnings\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn import linear_model\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from fuzzywuzzy import fuzz\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "plt.rcParams[\"patch.force_edgecolor\"] = True\n",
    "plt.style.use('fivethirtyeight')\n",
    "mpl.rc('patch', edgecolor = 'dimgray', linewidth=1)\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"last_expr\"\n",
    "pd.options.display.max_columns = 50\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n",
    "PS = nltk.stem.PorterStemmer()\n",
    "#__________________\n",
    "# load the dataset\n",
    "credits = load_tmdb_credits(\"/home/digipodium/Desktop/tmdb_5000_credits.csv.zip\")\n",
    "movies = load_tmdb_movies(\"/home/digipodium/Desktop/tmdb_5000_movies.csv.zip\")\n",
    "df_initial = convert_to_original_format(movies, credits)\n",
    "print('Shape:',df_initial.shape)\n",
    "#__________________________________________\n",
    "# info on variable types and filling factor\n",
    "tab_info=pd.DataFrame(df_initial.dtypes).T.rename(index={0:'column type'})\n",
    "tab_info=tab_info.append(pd.DataFrame(df_initial.isnull().sum()).T.rename(index={0:'null values'}))\n",
    "tab_info=tab_info.append(pd.DataFrame(df_initial.isnull().sum()/df_initial.shape[0]*100).T.\n",
    "                         rename(index={0:'null values (%)'}))\n",
    "tab_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set_keywords = set()\n",
    "for liste_keywords in df_initial['plot_keywords'].str.split('|').values:\n",
    "    if isinstance(liste_keywords, float): continue  # only happen if liste_keywords = NaN\n",
    "    set_keywords = set_keywords.union(liste_keywords)\n",
    "#_________________________\n",
    "# remove null chain entry\n",
    "set_keywords.remove('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_word(df, ref_col, liste):\n",
    "    keyword_count = dict()\n",
    "    for s in liste: keyword_count[s] = 0\n",
    "    for liste_keywords in df[ref_col].str.split('|'):        \n",
    "        if type(liste_keywords) == float and pd.isnull(liste_keywords): continue        \n",
    "        for s in [s for s in liste_keywords if s in liste]: \n",
    "            if pd.notnull(s): keyword_count[s] += 1\n",
    "    #______________________________________________________________________\n",
    "    # convert the dictionary in a list to sort the keywords by frequency\n",
    "    keyword_occurences = []\n",
    "    for k,v in keyword_count.items():\n",
    "        keyword_occurences.append([k,v])\n",
    "    keyword_occurences.sort(key = lambda x:x[1], reverse = True)\n",
    "    return keyword_occurences, keyword_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_occurences, dum = count_word(df_initial, 'plot_keywords', set_keywords)\n",
    "keyword_occurences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_color_func(word=None, font_size=None, position=None,\n",
    "                      orientation=None, font_path=None, random_state=None):\n",
    "    h = int(360.0 * tone / 255.0)\n",
    "    s = int(100.0 * 255.0 / 255.0)\n",
    "    l = int(100.0 * float(random_state.randint(70, 120)) / 255.0)\n",
    "    return \"hsl({}, {}%, {}%)\".format(h, s, l)\n",
    "#_____________________________________________\n",
    "# UPPER PANEL: WORDCLOUD\n",
    "fig = plt.figure(1, figsize=(18,13))\n",
    "ax1 = fig.add_subplot(2,1,1)\n",
    "#_______________________________________________________\n",
    "# I define the dictionary used to produce the wordcloud\n",
    "words = dict()\n",
    "trunc_occurences = keyword_occurences[0:50]\n",
    "for s in trunc_occurences:\n",
    "    words[s[0]] = s[1]\n",
    "tone = 55.0 # define the color of the words\n",
    "#________________________________________________________\n",
    "wordcloud = WordCloud(width=1000,height=300, background_color='black', \n",
    "                      max_words=1628,relative_scaling=1,\n",
    "                      color_func = random_color_func,\n",
    "                      normalize_plurals=False)\n",
    "wordcloud.generate_from_frequencies(words)\n",
    "ax1.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "ax1.axis('off')\n",
    "#_____________________________________________\n",
    "# LOWER PANEL: HISTOGRAMS\n",
    "ax2 = fig.add_subplot(2,1,2)\n",
    "y_axis = [i[1] for i in trunc_occurences]\n",
    "x_axis = [k for k,i in enumerate(trunc_occurences)]\n",
    "x_label = [i[0] for i in trunc_occurences]\n",
    "plt.xticks(rotation=85, fontsize = 15)\n",
    "plt.yticks(fontsize = 15)\n",
    "plt.xticks(x_axis, x_label)\n",
    "plt.ylabel(\"Nb. of occurences\", fontsize = 18, labelpad = 10)\n",
    "ax2.bar(x_axis, y_axis, align = 'center', color='g')\n",
    "#_______________________\n",
    "plt.title(\"Keywords popularity\",bbox={'facecolor':'k', 'pad':5},color='w',fontsize = 25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_df = df_initial.isnull().sum(axis=0).reset_index()\n",
    "missing_df.columns = ['column_name', 'missing_count']\n",
    "missing_df['filling_factor'] = (df_initial.shape[0] \n",
    "                                - missing_df['missing_count']) / df_initial.shape[0] * 100\n",
    "missing_df.sort_values('filling_factor').reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_initial['decade'] = df_initial['title_year'].apply(lambda x:((x-1900)//10)*10)\n",
    "#__________________________________________________________________\n",
    "# function that extract statistical parameters from a grouby objet:\n",
    "def get_stats(gr):\n",
    "    return {'min':gr.min(),'max':gr.max(),'count': gr.count(),'mean':gr.mean()}\n",
    "#______________________________________________________________\n",
    "# Creation of a dataframe with statitical infos on each decade:\n",
    "test = df_initial['title_year'].groupby(df_initial['decade']).apply(get_stats).unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"poster\", font_scale=0.85)\n",
    "#_______________________________\n",
    "# funtion used to set the labels\n",
    "def label(s):\n",
    "    val = (1900 + s, s)[s < 100]\n",
    "    chaine = '' if s < 50 else \"{}'s\".format(int(val))\n",
    "    return chaine\n",
    "#____________________________________\n",
    "plt.rc('font', weight='bold')\n",
    "f, ax = plt.subplots(figsize=(11, 6))\n",
    "labels = [label(s) for s in  test.index]\n",
    "sizes  = test['count'].values\n",
    "explode = [0.2 if sizes[i] < 100 else 0.01 for i in range(11)]\n",
    "ax.pie(sizes, explode = explode, labels=labels,\n",
    "       autopct = lambda x:'{:1.0f}%'.format(x) if x > 1 else '',\n",
    "       shadow=False, startangle=0)\n",
    "ax.axis('equal')\n",
    "ax.set_title('% of films per decade',\n",
    "             bbox={'facecolor':'k', 'pad':5},color='w', fontsize=16);\n",
    "df_initial.drop('decade', axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genre_labels = set()\n",
    "for s in df_initial['genres'].str.split('|').values:\n",
    "    genre_labels = genre_labels.union(set(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_occurences, dum = count_word(df_initial, 'genres', genre_labels)\n",
    "keyword_occurences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# words = dict()\n",
    "# trunc_occurences = keyword_occurences[0:50]\n",
    "# for s in trunc_occurences:\n",
    "#     words[s[0]] = s[1]\n",
    "# tone = 100 # define the color of the words\n",
    "# f, ax = plt.subplots(figsize=(14, 6))\n",
    "# wordcloud = WordCloud(width=550,height=300, background_color='black', \n",
    "#                       max_words=1628,relative_scaling=0.7,\n",
    "#                       color_func = random_color_func,\n",
    "#                       )\n",
    "# wordcloud.generate_from_frequencies(words)\n",
    "# plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "# plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_duplicate_cleaned = df_initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def keywords_inventory(dataframe, colonne = 'plot_keywords'):\n",
    "    PS = nltk.stem.PorterStemmer()\n",
    "    keywords_roots  = dict()  # collect the words / root\n",
    "    keywords_select = dict()  # association: root <-> keyword\n",
    "    category_keys = []\n",
    "    icount = 0\n",
    "    for s in dataframe[colonne]:\n",
    "        if pd.isnull(s): continue\n",
    "        for t in s.split('|'):\n",
    "            t = t.lower() ; racine = PS.stem(t)\n",
    "            if racine in keywords_roots:                \n",
    "                keywords_roots[racine].add(t)\n",
    "            else:\n",
    "                keywords_roots[racine] = {t}\n",
    "    \n",
    "    for s in keywords_roots.keys():\n",
    "        if len(keywords_roots[s]) > 1:  \n",
    "            min_length = 1000\n",
    "            for k in keywords_roots[s]:\n",
    "                if len(k) < min_length:\n",
    "                    clef = k ; min_length = len(k)            \n",
    "            category_keys.append(clef)\n",
    "            keywords_select[s] = clef\n",
    "        else:\n",
    "            category_keys.append(list(keywords_roots[s])[0])\n",
    "            keywords_select[s] = list(keywords_roots[s])[0]\n",
    "                   \n",
    "    print(\"Nb of keywords in variable '{}': {}\".format(colonne,len(category_keys)))\n",
    "    return category_keys, keywords_roots, keywords_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords, keywords_roots, keywords_select = keywords_inventory(df_duplicate_cleaned,\n",
    "                                                               colonne = 'plot_keywords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icount = 0\n",
    "for s in keywords_roots.keys():\n",
    "    if len(keywords_roots[s]) > 1: \n",
    "        icount += 1\n",
    "        if icount < 15: print(icount, keywords_roots[s], len(keywords_roots[s]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remplacement_df_keywords(df, dico_remplacement, roots = False):\n",
    "    df_new = df.copy(deep = True)\n",
    "    for index, row in df_new.iterrows():\n",
    "        chaine = row['plot_keywords']\n",
    "        if pd.isnull(chaine): continue\n",
    "        nouvelle_liste = []\n",
    "        for s in chaine.split('|'): \n",
    "            clef = PS.stem(s) if roots else s\n",
    "            if clef in dico_remplacement.keys():\n",
    "                nouvelle_liste.append(dico_remplacement[clef])\n",
    "            else:\n",
    "                nouvelle_liste.append(s)       \n",
    "        df_new.set_value(index, 'plot_keywords', '|'.join(nouvelle_liste)) \n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_keywords_cleaned = remplacement_df_keywords(df_duplicate_cleaned, keywords_select,\n",
    "                                               roots = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords.remove('')\n",
    "keyword_occurences, keywords_count = count_word(df_keywords_cleaned,'plot_keywords',keywords)\n",
    "keyword_occurences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_synonymes(mot_cle):\n",
    "    lemma = set()\n",
    "    for ss in wordnet.synsets(mot_cle):\n",
    "        for w in ss.lemma_names():\n",
    "            #_______________________________\n",
    "            # We just get the 'nouns':\n",
    "            index = ss.name().find('.')+1\n",
    "            if ss.name()[index] == 'n': lemma.add(w.lower().replace('_',' '))\n",
    "    return lemma   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mot_cle = 'alien'\n",
    "lemma = get_synonymes(mot_cle)\n",
    "for s in lemma:\n",
    "    print(' \"{:<30}\" in keywords list -> {} {}'.format(s, s in keywords,\n",
    "                                                keywords_count[s] if s in keywords else 0 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_keyword(mot, key_count, threshold):\n",
    "    return (False , True)[key_count.get(mot, 0) >= threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_occurences.sort(key = lambda x:x[1], reverse = False)\n",
    "key_count = dict()\n",
    "for s in keyword_occurences:\n",
    "    key_count[s[0]] = s[1]\n",
    "#__________________________________________________________________________\n",
    "# Creation of a dictionary to replace keywords by higher frequency keywords\n",
    "remplacement_mot = dict()\n",
    "icount = 0\n",
    "for index, [mot, nb_apparitions] in enumerate(keyword_occurences):\n",
    "    if nb_apparitions > 5: continue  # only the keywords that appear less than 5 times\n",
    "    lemma = get_synonymes(mot)\n",
    "    if len(lemma) == 0: continue     # case of the plurals\n",
    "    #_________________________________________________________________\n",
    "    liste_mots = [(s, key_count[s]) for s in lemma \n",
    "                  if test_keyword(s, key_count, key_count[mot])]\n",
    "    liste_mots.sort(key = lambda x:(x[1],x[0]), reverse = True)    \n",
    "    if len(liste_mots) <= 1: continue       # no replacement\n",
    "    if mot == liste_mots[0][0]: continue    # replacement by himself\n",
    "    icount += 1\n",
    "    if  icount < 8:\n",
    "        print('{:<12} -> {:<12} (init: {})'.format(mot, liste_mots[0][0], liste_mots))    \n",
    "    remplacement_mot[mot] = liste_mots[0][0]\n",
    "\n",
    "print(90*'_'+'\\n'+'The replacement concerns {}% of the keywords.'\n",
    "      .format(round(len(remplacement_mot)/len(keywords)*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Keywords that appear both in keys and values:'.upper()+'\\n'+45*'-')\n",
    "icount = 0\n",
    "for s in remplacement_mot.values():\n",
    "    if s in remplacement_mot.keys():\n",
    "        icount += 1\n",
    "        if icount < 10: print('{:<20} -> {:<20}'.format(s, remplacement_mot[s]))\n",
    "\n",
    "for key, value in remplacement_mot.items():\n",
    "    if value in remplacement_mot.keys():\n",
    "        remplacement_mot[key] = remplacement_mot[value]      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_keywords_synonyms = \\\n",
    "            remplacement_df_keywords(df_keywords_cleaned, remplacement_mot, roots = False)   \n",
    "keywords, keywords_roots, keywords_select = \\\n",
    "            keywords_inventory(df_keywords_synonyms, colonne = 'plot_keywords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords.remove('')\n",
    "new_keyword_occurences, keywords_count = count_word(df_keywords_synonyms,\n",
    "                                                    'plot_keywords',keywords)\n",
    "new_keyword_occurences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remplacement_df_low_frequency_keywords(df, keyword_occurences):\n",
    "    df_new = df.copy(deep = True)\n",
    "    key_count = dict()\n",
    "    for s in keyword_occurences: \n",
    "        key_count[s[0]] = s[1]    \n",
    "    for index, row in df_new.iterrows():\n",
    "        chaine = row['plot_keywords']\n",
    "        if pd.isnull(chaine): continue\n",
    "        nouvelle_liste = []\n",
    "        for s in chaine.split('|'): \n",
    "            if key_count.get(s, 4) > 3: nouvelle_liste.append(s)\n",
    "        df_new.set_value(index, 'plot_keywords', '|'.join(nouvelle_liste))\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_keywords_occurence = \\\n",
    "    remplacement_df_low_frequency_keywords(df_keywords_synonyms, new_keyword_occurences)\n",
    "keywords, keywords_roots, keywords_select = \\\n",
    "    keywords_inventory(df_keywords_occurence, colonne = 'plot_keywords')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords.remove('')\n",
    "new_keyword_occurences, keywords_count = count_word(df_keywords_occurence,\n",
    "                                                    'plot_keywords',keywords)\n",
    "new_keyword_occurences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {'family' : 'fantasy', 'weight' : 'normal', 'size'   : 15}\n",
    "mpl.rc('font', **font)\n",
    "\n",
    "keyword_occurences.sort(key = lambda x:x[1], reverse = True)\n",
    "\n",
    "y_axis = [i[1] for i in keyword_occurences]\n",
    "x_axis = [k for k,i in enumerate(keyword_occurences)]\n",
    "\n",
    "new_y_axis = [i[1] for i in new_keyword_occurences]\n",
    "new_x_axis = [k for k,i in enumerate(new_keyword_occurences)]\n",
    "\n",
    "f, ax = plt.subplots(figsize=(9, 5))\n",
    "ax.plot(x_axis, y_axis, 'r-', label='before cleaning')\n",
    "ax.plot(new_x_axis, new_y_axis, 'b-', label='after cleaning')\n",
    "\n",
    "# Now add the legend with some customizations.\n",
    "legend = ax.legend(loc='upper right', shadow=True)\n",
    "frame = legend.get_frame()\n",
    "frame.set_facecolor('0.90')\n",
    "for label in legend.get_texts():\n",
    "    label.set_fontsize('medium')\n",
    "            \n",
    "plt.ylim((0,25))\n",
    "plt.axhline(y=3.5, linewidth=2, color = 'k')\n",
    "plt.xlabel(\"keywords index\", family='fantasy', fontsize = 15)\n",
    "plt.ylabel(\"Nb. of occurences\", family='fantasy', fontsize = 15)\n",
    "#plt.suptitle(\"Nombre d'occurences des mots clÃ©s\", fontsize = 18, family='fantasy')\n",
    "plt.text(3500, 4.5, 'threshold for keyword delation', fontsize = 13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 9))\n",
    "#_____________________________\n",
    "# calculations of correlations\n",
    "corrmat = df_keywords_occurence.dropna(how='any').corr()\n",
    "#________________________________________\n",
    "k = 17 # number of variables for heatmap\n",
    "cols = corrmat.nlargest(k, 'num_voted_users')['num_voted_users'].index\n",
    "cm = np.corrcoef(df_keywords_occurence[cols].dropna(how='any').values.T)\n",
    "sns.set(font_scale=1.25)\n",
    "hm = sns.heatmap(cm, cbar=True, annot=True, square=True,\n",
    "                 fmt='.2f', annot_kws={'size': 10}, linewidth = 0.1, cmap = 'coolwarm',\n",
    "                 yticklabels=cols.values, xticklabels=cols.values)\n",
    "f.text(0.5, 0.93, \"Correlation coefficients\", ha='center', fontsize = 18, family='fantasy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_var_cleaned = df_keywords_occurence.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_df = df_var_cleaned.isnull().sum(axis=0).reset_index()\n",
    "missing_df.columns = ['column_name', 'missing_count']\n",
    "missing_df['filling_factor'] = (df_var_cleaned.shape[0] \n",
    "                                - missing_df['missing_count']) / df_var_cleaned.shape[0] * 100\n",
    "missing_df = missing_df.sort_values('filling_factor').reset_index(drop = True)\n",
    "missing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_axis = missing_df['filling_factor'] \n",
    "x_label = missing_df['column_name']\n",
    "x_axis = missing_df.index\n",
    "\n",
    "fig = plt.figure(figsize=(11, 4))\n",
    "plt.xticks(rotation=80, fontsize = 14)\n",
    "plt.yticks(fontsize = 13)\n",
    "\n",
    "N_thresh = 5\n",
    "plt.axvline(x=N_thresh-0.5, linewidth=2, color = 'r')\n",
    "plt.text(N_thresh-4.8, 30, 'filling factor \\n < {}%'.format(round(y_axis[N_thresh],1)),\n",
    "         fontsize = 15, family = 'fantasy', bbox=dict(boxstyle=\"round\",\n",
    "                   ec=(1.0, 0.5, 0.5),\n",
    "                   fc=(0.8, 0.5, 0.5)))\n",
    "N_thresh = 17\n",
    "plt.axvline(x=N_thresh-0.5, linewidth=2, color = 'g')\n",
    "plt.text(N_thresh, 30, 'filling factor \\n = {}%'.format(round(y_axis[N_thresh],1)),\n",
    "         fontsize = 15, family = 'fantasy', bbox=dict(boxstyle=\"round\",\n",
    "                   ec=(1., 0.5, 0.5),\n",
    "                   fc=(0.5, 0.8, 0.5)))\n",
    "\n",
    "plt.xticks(x_axis, x_label,family='fantasy', fontsize = 14 )\n",
    "plt.ylabel('Filling factor (%)', family='fantasy', fontsize = 16)\n",
    "plt.bar(x_axis, y_axis);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
